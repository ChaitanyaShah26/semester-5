{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMCpNAZ/5hfCeTnbflk3DNJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# NLP Experiment-5\n"],"metadata":{"id":"LIu_hPAJo1Xe"}},{"cell_type":"code","source":["import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.tag import pos_tag\n","from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import wordnet\n","\n","nltk.download('punkt_tab')\n","nltk.download('averaged_perceptron_tagger_eng')\n","nltk.download('wordnet')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3WQJgzDtzzZz","executionInfo":{"status":"ok","timestamp":1757394634749,"user_tz":-330,"elapsed":21,"user":{"displayName":"Chaitanya","userId":"00734284376877800923"}},"outputId":"5a812b35-ae60-4565-b2b9-d76573ddee26"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":56}]},{"cell_type":"markdown","source":["Input Text"],"metadata":{"id":"Rovk85kWz-xz"}},{"cell_type":"code","source":["text = \"\"\"\n","Machine learning is the subset of artificial intelligence (AI) focused on algorithms that can “learn” the patterns of training data and, subsequently, make accurate inferences about new data. This pattern recognition ability enables machine learning models to make decisions or predictions without explicit, hard-coded instructions.\n","\"\"\""],"metadata":{"id":"s1WENINa0Af0","executionInfo":{"status":"ok","timestamp":1757394635148,"user_tz":-330,"elapsed":82,"user":{"displayName":"Chaitanya","userId":"00734284376877800923"}}},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":["Tokenization"],"metadata":{"id":"HrLqUvjRz6gE"}},{"cell_type":"code","source":["text = \"This is a sample sentence for NLTK tokenization.\"\n","tokens = word_tokenize(text)\n","print(tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zk3ME0gXzgwN","executionInfo":{"status":"ok","timestamp":1757394635430,"user_tz":-330,"elapsed":4,"user":{"displayName":"Chaitanya","userId":"00734284376877800923"}},"outputId":"62c1a343-7882-4fa0-b5d1-c42dfbea61fd"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["['This', 'is', 'a', 'sample', 'sentence', 'for', 'NLTK', 'tokenization', '.']\n"]}]},{"cell_type":"markdown","source":["POS Tagging"],"metadata":{"id":"u_MSNISh0Tjc"}},{"cell_type":"code","source":["tokens = word_tokenize(text)\n","POS_tags = pos_tag(tokens)\n","print(POS_tags)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sA4QBXGx0Oxe","executionInfo":{"status":"ok","timestamp":1757394635727,"user_tz":-330,"elapsed":26,"user":{"displayName":"Chaitanya","userId":"00734284376877800923"}},"outputId":"6ab21819-c9c2-4092-e218-54799dd87f50"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["[('This', 'DT'), ('is', 'VBZ'), ('a', 'DT'), ('sample', 'JJ'), ('sentence', 'NN'), ('for', 'IN'), ('NLTK', 'NNP'), ('tokenization', 'NN'), ('.', '.')]\n"]}]},{"cell_type":"markdown","source":["Map POS Tags to WordNet POS"],"metadata":{"id":"VrdOtSMX0pfr"}},{"cell_type":"code","source":["def get_wordnet_pos(tag):\n","    if tag.startswith('J'):\n","        return wordnet.ADJ\n","    elif tag.startswith('V'):\n","        return wordnet.VERB\n","    elif tag.startswith('N'):\n","        return wordnet.NOUN\n","    elif tag.startswith('R'):\n","        return wordnet.ADV\n","    else:\n","        return None"],"metadata":{"id":"1rBvPq7v0i6d","executionInfo":{"status":"ok","timestamp":1757394636484,"user_tz":-330,"elapsed":15,"user":{"displayName":"Chaitanya","userId":"00734284376877800923"}}},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":["Lemmatization using WordNet"],"metadata":{"id":"xLwx0fOh0tmU"}},{"cell_type":"code","source":["lemmatizer = WordNetLemmatizer()"],"metadata":{"id":"0xh9v6D50vJ1","executionInfo":{"status":"ok","timestamp":1757394637412,"user_tz":-330,"elapsed":8,"user":{"displayName":"Chaitanya","userId":"00734284376877800923"}}},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":["Output"],"metadata":{"id":"qQq7avOh0vjM"}},{"cell_type":"code","source":["for token, pos_tag in POS_tags:\n","    wordnet_pos = get_wordnet_pos(pos_tag)\n","    if wordnet_pos:\n","        lemma = lemmatizer.lemmatize(token, wordnet_pos)\n","        print((token, pos_tag, wordnet_pos, lemma))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KJrz0my10w91","executionInfo":{"status":"ok","timestamp":1757394712696,"user_tz":-330,"elapsed":56,"user":{"displayName":"Chaitanya","userId":"00734284376877800923"}},"outputId":"81950184-ae26-44e5-c470-9cc616558e37"},"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["('is', 'VBZ', 'v', 'be')\n","('sample', 'JJ', 'a', 'sample')\n","('sentence', 'NN', 'n', 'sentence')\n","('NLTK', 'NNP', 'n', 'NLTK')\n","('tokenization', 'NN', 'n', 'tokenization')\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"jp7Af_lY4fjl"},"execution_count":null,"outputs":[]}]}